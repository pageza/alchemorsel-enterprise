version: '3.8'

# Alchemorsel v3 - Service-Separated Docker Compose
# Based on ADR-0003: Docker Compose Architecture with Service Separation

services:
  # PostgreSQL Database (as per ADR-0002: PostgreSQL-only)
  postgres:
    image: postgres:15-alpine
    container_name: alchemorsel-postgres
    environment:
      POSTGRES_DB: alchemorsel_dev
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d alchemorsel_dev"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - alchemorsel-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: alchemorsel-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - alchemorsel-network

  # Pure JSON API Backend Service
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: alchemorsel-api
    environment:
      # Database configuration (ADR-0002: PostgreSQL-only)
      ALCHEMORSEL_DATABASE_HOST: postgres
      ALCHEMORSEL_DATABASE_PORT: 5432
      ALCHEMORSEL_DATABASE_DATABASE: alchemorsel_dev
      ALCHEMORSEL_DATABASE_USERNAME: postgres
      ALCHEMORSEL_DATABASE_PASSWORD: postgres
      ALCHEMORSEL_DATABASE_SSLMODE: disable
      
      # Redis configuration
      ALCHEMORSEL_REDIS_HOST: redis
      ALCHEMORSEL_REDIS_PORT: 6379
      
      # Application configuration
      ALCHEMORSEL_APP_ENVIRONMENT: development
      ALCHEMORSEL_APP_DEBUG: "true"
      ALCHEMORSEL_APP_VERSION: v3.0.0
      
      # Security configuration
      ALCHEMORSEL_AUTH_JWT_SECRET: "development-jwt-secret-key-change-in-production"
      
      # API server port (allocated via portscan: 3010)
      PORT: 3010
      
      # Metrics endpoint port (allocated via portscan: 3012)
      ALCHEMORSEL_MONITORING_METRICS_PORT: 3012
      
      # AI configuration (using containerized Ollama)
      ALCHEMORSEL_AI_PROVIDER: ollama
      ALCHEMORSEL_OLLAMA_HOST: http://ollama:11434
      ALCHEMORSEL_OLLAMA_MODEL: llama3.2:3b
      
      # Enterprise health check configuration
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_ENTERPRISE: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_METRICS: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_CIRCUIT_BREAKER: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_DEPENDENCIES: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CACHE_TTL: "5s"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_TIMEOUT: "10s"
      
      # Circuit breaker configuration
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_FAILURE_THRESHOLD: 5
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_SUCCESS_THRESHOLD: 2
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_TIMEOUT: "30s"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_MAX_REQUESTS: 3
    ports:
      - "3010:3010"  # Pure API service port (portscan allocated)
      - "3012:3012"  # Metrics endpoint port (portscan allocated)
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "/app/health-check", "--url=http://localhost:3010/health", "--mode=standard", "--timeout=10s"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    networks:
      - alchemorsel-network
    restart: unless-stopped

  # Web Frontend Service (HTMX Templates)
  web:
    build:
      context: .
      dockerfile: Dockerfile.web
    container_name: alchemorsel-web
    environment:
      # API Backend connection (updated for portscan allocated port)
      API_URL: http://api:3010
      
      # Application configuration
      ALCHEMORSEL_APP_ENVIRONMENT: development
      ALCHEMORSEL_APP_DEBUG: "true"
      ALCHEMORSEL_APP_VERSION: v3.0.0
      
      # Web server port (allocated via portscan: 3011)
      PORT: 3011
      
      # Enterprise health check configuration
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_ENTERPRISE: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_METRICS: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_CIRCUIT_BREAKER: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_ENABLE_DEPENDENCIES: "true"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CACHE_TTL: "5s"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_TIMEOUT: "10s"
      
      # Circuit breaker configuration for API dependency
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_FAILURE_THRESHOLD: 3
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_SUCCESS_THRESHOLD: 2
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_TIMEOUT: "30s"
      ALCHEMORSEL_MONITORING_HEALTH_CHECK_CIRCUIT_BREAKER_MAX_REQUESTS: 2
    ports:
      - "3011:3011"  # Web frontend port (portscan allocated)
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "/app/health-check", "--url=http://localhost:3011/health", "--mode=standard", "--timeout=10s"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    networks:
      - alchemorsel-network
    restart: unless-stopped

  # Jaeger (Distributed Tracing) - Optional for development
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: alchemorsel-jaeger
    environment:
      COLLECTOR_OTLP_ENABLED: true
    ports:
      - "16686:16686"  # Jaeger UI
      - "14250:14250"  # gRPC
      - "14268:14268"  # HTTP
    networks:
      - alchemorsel-network
    profiles:
      - observability

  # Prometheus (Metrics) - Optional for development
  prometheus:
    image: prom/prometheus:latest
    container_name: alchemorsel-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./deployments/observability/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    depends_on:
      - api
      - web
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - alchemorsel-network
    profiles:
      - observability

  # Grafana (Metrics Visualization) - Optional for development
  grafana:
    image: grafana/grafana:latest
    container_name: alchemorsel-grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: admin
    ports:
      - "3013:3000"  # Changed to avoid conflict with allocated ports
    volumes:
      - grafana_data:/var/lib/grafana
      - ./deployments/docker/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./deployments/docker/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - alchemorsel-network
    profiles:
      - observability

  # Ollama AI Service (Containerized Local AI Inference)
  ollama:
    build:
      context: .
      dockerfile: deployments/ollama/Dockerfile
    container_name: alchemorsel-ollama
    environment:
      # Ollama configuration for optimal performance
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_ORIGINS: "*"
      OLLAMA_NUM_PARALLEL: 2
      OLLAMA_MAX_LOADED_MODELS: 2
      OLLAMA_DEBUG: "false"
      OLLAMA_FLASH_ATTENTION: "false"
      OLLAMA_LLM_LIBRARY: cpu
      OLLAMA_NOPRUNE: "false"
      
      # Model configuration
      OLLAMA_DEFAULT_MODEL: llama3.2:3b
      OLLAMA_PRELOAD_MODELS: "llama3.2:3b"
      OLLAMA_MODEL_TIMEOUT: 600
      OLLAMA_MAX_RETRIES: 3
      
      # Health check configuration
      OLLAMA_HEALTH_TIMEOUT: 30
      
      # Resource optimization
      OLLAMA_RUNNER_SLEEP: 10s
      OLLAMA_TMPDIR: /tmp
    ports:
      - "11435:11434"  # External port mapping (ADR-0005 port allocation)
    volumes:
      # Persistent model storage
      - ollama_models:/root/.ollama
      # Configuration and scripts
      - ./deployments/ollama/scripts:/scripts:ro
      - ./deployments/ollama/health:/health:ro
    networks:
      - alchemorsel-network
    healthcheck:
      test: [
        "CMD", 
        "/health/healthcheck.sh"
      ]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 180s  # Extended startup time for model loading
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'
    # GPU support (uncomment for NVIDIA GPU acceleration)
    # runtime: nvidia
    # environment:
    #   NVIDIA_VISIBLE_DEVICES: all
    #   OLLAMA_LLM_LIBRARY: cuda
    #   OLLAMA_GPU_OVERHEAD: 1024M
    labels:
      - "com.docker.compose.service=ollama"
      - "monitoring.enable=true"
      - "ai.model=llama3.2:3b"
      - "ai.provider=ollama"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  ollama_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/ollama
    labels:
      - "service=ollama"
      - "type=models"

networks:
  alchemorsel-network:
    driver: bridge
    name: alchemorsel-v3